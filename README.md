Support Vector Machines (SVM) are supervised learning models used for classification and regression tasks. SVM aims to find the hyperplane that best separates data into different classes by maximizing the margin (distance) between the hyperplane and the nearest data points (support vectors). In classification, SVM seeks to find the optimal hyperplane that separates classes with the largest margin, often using a kernel trick to handle non-linear separations. In regression, SVM predicts continuous outcomes by fitting a hyperplane that best approximates the data. SVM is effective in high-dimensional spaces and is robust against overfitting, especially with appropriate kernel functions like radial basis function (RBF) or polynomial kernels.
